\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}



\title{Math 106 -- Notes \\ Week 4: January 26, 2026}
\author{Ethan Levien}
\date{}

\begin{document}
\maketitle


\section*{General continuous time Markov processes (5.3)}

Now we switch back to talking about Markov processes. Eventually we will answer the question: Which Gaussian processes are also Markov processes. A Markov process is defined as follows. 
\begin{definition}[Markov processes]
Let $(\Omega,{\mathcal F},{\mathbb P})$ be a probability space. A process $X_t$ is a Markov processes  if it is ${\mathcal F}_t$-adopted processes and for $s \le t$ and $B \in {\mathcal R}$
\begin{equation}
 {\mathbb P}(X_t \in B|{\mathcal F_s}) =  {\mathbb P}(X_t \in B|X_s)
\end{equation}
\end{definition}

We will consider homogenous Markov processes which are defined by a transition function
\begin{equation}
p(t,x,B) =  {\mathbb P}(X_t \in B|X_0 = x)
\end{equation}
we also define an linear operator 
\begin{equation}
T_tf(x) = {\mathbb E}[f(X_t)|X_0 = x] 
\end{equation}
If there is a density $\rho(t,x,y)$ such that $p(t,x,[y,y+dy))  \approx \rho(t,x,y)dy$, then this becomes
\begin{equation}
T_tf(x) = \int f(y) \rho(t,x,y)dy
\end{equation}
A considerable amount of time will later be spent studying the PDE for $\rho$, but first we spend a bit more time on the general case. 

Note that $p(t,x,B)$ and $T_tf(x)$ correspond respectively to the notation $P_{i,j}(t)$ and $h_{i}(t)$ which was introduced for $Q$-processes.  Let $f$ be bounded and measurable. Using time–homogeneity and the Markov property,
\begin{align}
T_t(T_s f)(x)
&= {\mathbb E}\bigl[T_s f(X_t)\mid X_0=x\bigr] \label{eq:calc1}\\
&= {\mathbb E}\bigl[{\mathbb E}[f(X_{t+s})\mid X_t]\mid X_0=x\bigr] \label{eq:calc2}\\
&= {\mathbb E}[f(X_{t+s})\mid X_0=x] \label{eq:calc3}\\
&= T_{t+s}f(x). \label{eq:calc4}
\end{align}
Moreover $T_0 f(x)=f(x)$. Thus $\{T_t\}_{t\ge 0}$ satisfies
\begin{equation}\label{eq:semigroup}
T_0=I, \qquad T_{t+s}=T_tT_s,
\end{equation}
and is a semigroup of linear operators.

\subsection*{A brief detour: semigroup theory}

We now pause to introduce the basic semigroup language needed later. This material provides the abstract framework that connects Markov processes, PDEs, and generators.

\begin{definition}[Strongly continuous semigroup]
Let $X$ be a Banach space. A family of linear operators $\{T_t\}_{t\ge 0}$ on $X$ is called a (strongly continuous) semigroup if
\begin{align}
T_0 &= I, \label{eq:sg-identity}\\
T_{t+s} &= T_t T_s, \qquad t,s\ge 0, \label{eq:sg-law}\\
\lim_{t\downarrow 0}\|T_t f - f\| &= 0 \quad \text{for all } f\in X. \label{eq:sg-strong}
\end{align}
The continuity condition \eqref{eq:sg-strong} is called \emph{strong continuity}.
\end{definition}

The Markov operators $\{T_t\}$ constructed above always satisfy the algebraic properties
\eqref{eq:sg-identity}–\eqref{eq:sg-law}. The additional requirement \eqref{eq:sg-strong} expresses the idea that the process evolves continuously in time when tested against observables $f$.

\paragraph{Why strong, not uniform, continuity?}
A stronger notion would be \emph{uniform continuity}, which requires
\begin{equation}\label{eq:uniform-cont}
\|T_t - I\| \to 0 \quad \text{as } t\downarrow 0,
\end{equation}
where $\|\cdot\|$ denotes the operator norm on $X$. Recall that for a bounded linear operator $S:X\to X$,
\begin{equation}\label{eq:operator-norm}
\|S\|
\;=\;
\sup_{\|f\|\le 1}\|Sf\|
\;=\;
\sup_{f\neq 0}\frac{\|Sf\|}{\|f\|}.
\end{equation}
Thus \eqref{eq:uniform-cont} means that
\begin{equation}\label{eq:uniform-cont-meaning}
\sup_{\|f\|\le 1}\|(T_t-I)f\| \longrightarrow 0 \qquad \text{as } t\downarrow 0,
\end{equation}
i.e.\ \emph{every} function in the unit ball of $X$ is moved only a small amount, uniformly over all such functions, for sufficiently small times.

This requirement is too restrictive for most semigroups arising in probability. A canonical example is the translation semigroup on functions on $\mathbb{R}$,
\begin{equation}\label{eq:translation}
(T_t f)(x) = f(x+t).
\end{equation}
On spaces such as $C_0(\mathbb{R})$ or $L^p(\mathbb{R})$, this semigroup is strongly continuous: for each fixed $f$, small translations produce small changes in norm. However, it is \emph{not} uniformly continuous. Intuitively, one can construct functions with arbitrarily sharp spatial features, for which even a tiny translation produces an $O(1)$ change in norm. Thus \eqref{eq:uniform-cont} fails, even though \eqref{eq:sg-strong} holds.

This example shows that strong continuity is the correct level of regularity if one wants a theory broad enough to include translation, diffusion, and Markov semigroups.

\paragraph{Infinitesimal generator.}
Given a strongly continuous semigroup $\{T_t\}$, its infinitesimal generator ${\mathcal A}$ is defined by
\begin{equation}\label{eq:generator}
{\mathcal A}f
= \lim_{t\downarrow 0}\frac{T_t f - f}{t},
\end{equation}
for all $f$ in the domain $\mathcal D({\mathcal A})$ where the limit exists. The generator describes the instantaneous rate of change of observables.

For the translation semigroup \eqref{eq:translation}, a direct calculation shows that
\begin{equation}\label{eq:translation-generator}
{\mathcal A}f = f',
\end{equation}
with domain consisting of (say) continuously differentiable functions vanishing at infinity. Thus the semigroup of translations is generated by the first derivative operator.

\paragraph{From generators to semigroups.}
Formally, the semigroup solves the abstract evolution equation
\begin{equation}\label{eq:abstract-evolution}
\partial_t u_t = {\mathcal A}u_t, \qquad u_0 = f,
\end{equation}
with solution $u_t = T_t f$. For Markov processes, ${\mathcal A}$ is the object that appears most naturally:
\begin{itemize}
\item for $Q$-processes, ${\mathcal A}=Q$;
\item for diffusions, ${\mathcal A}$ is a second–order differential operator;
\item for jump processes, ${\mathcal A}$ is an integro–differential operator.
\end{itemize}

\paragraph{Resolvent operator.}
The resolvent associated with ${\mathcal A}$ is defined, for $\lambda>0$, by
\begin{equation}\label{eq:resolvent}
R_\lambda f = \int_0^\infty e^{-\lambda t} T_t f\,dt.
\end{equation}
It satisfies the resolvent identity
\begin{equation}\label{eq:resolvent-identity}
(\lambda I - {\mathcal A})R_\lambda f = f,
\end{equation}
at least on a suitable domain. The resolvent provides a bridge between the generator and the semigroup via Laplace transform in time.

\paragraph{Why generators are central.}
The generator ${\mathcal A}$ is local in time and typically has a simple analytic form, whereas the full semigroup $\{T_t\}$ encodes global-in-time behavior. Much of the theory of continuous-time Markov processes proceeds by specifying ${\mathcal A}$, proving it generates a strongly continuous semigroup, and then deducing properties of the process from the generator rather than from $T_t$ directly.




\end{document}