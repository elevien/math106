---
title: Week 1
layout: page
permalink: /Week1/
bibliography:
- refs.bib
---


## Probability theory background

I will assume a basic proficiency with (non-measure theoretic) probability theory. This means understanding the idea of sample spaces, outcomes, events, conditional probability, independence, marginalization, Bayes' theorem, Jenson's inequality, LLN and CLT. These are all covered in the textbook (1.1, 1.3, 1.4) and are easy to find elsewhere (or have GAI explain it). 

In terms of distributions, you should be comfortable with Bernoulli, Binomial, Exponential, Poisson and Normal distributions. I will cover multivariate normal, but it will not be the main event so if you have no or limited experience working with multivariate normal distribution, I recommend reviewing this. 

You can skim 1.2 and 1.5, but we will circle back to that later as preparation for the more abstract theory of stochastic processes. Markov chains with finite state spaces can be handled without any measure theory, so I will really begin with 3.1. 

## Discrete time Markov Chains

The main topic of week 1 will be discrete time Markov chains. 
The plan is to cover 

- Transition probabilities 
- Stochastic matrix
- P 3.4 (Chapman-Kolmogorov equation)
- Stationary distribution/invariant distribution
- L 3.5 (spectral radius of stochastic matrix)
- D 3.6 (Irreducibility)
- L 3.7
- **T 3.8** (this is not proved in the textbook, but I will provide a sketch of the proof at the expense of some other details in the text)
- D 1.10
- T 3.11






